<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="description" content="Hyundong Jin – Ph.D. candidate at Chung-Ang University, working on continual learning, multi-modal learning, and computer vision." />
  <title>Hyundong Jin</title>

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css2?family=DM+Serif+Display:ital@0;1&family=DM+Sans:ital,opsz,wght@0,9..40,300;0,9..40,400;0,9..40,500;0,9..40,600;1,9..40,300&display=swap" rel="stylesheet" />

  <link rel="stylesheet" href="assets/css/style.css" />
</head>
<body>

<!-- ═══════════ NAV ═══════════ -->
<header id="navbar">
  <a class="brand" href="#">Hyundong Jin</a>
  <nav>
    <a href="#about">About</a>
    <a href="#research">Research</a>
    <a href="#projects">Projects</a>
    <a href="#others">Others</a>
  </nav>
</header>


<div class="wrap">

<!-- ═══════════ HERO ═══════════ -->
<section id="hero">
  <div class="hero-inner">

    <img
      class="hero-photo"
      src="media/profile.jpg"
      alt="Hyundong Jin"
      onerror="this.style.display='none'"
    />

    <div>
      <h1 class="hero-name">Hyundong Jin (He/Him)</h1>
      <p class="hero-email">wlsgusehd@gmail.com</p>

      <div class="hero-bio">
        <p>
          I received my Ph.D. in the School of Computer Science and Engineering at
          <a href="https://vllab.cau.ac.kr/alumni/">Chung-Ang University (CAU)</a>
          in February 2026, advised by <a href="https://vllab.cau.ac.kr/members/professor/">Prof. Eunwoo Kim</a>.
          I also received my B.S. in Electrical and Electronics Engineering (2020) and
          M.S. in Computer Science and Engineering (2022), both from Chung-Ang University.
          I am currently looking for full-time research positions.
        </p>
        <p>
          Research expertise in <strong>continual learning<strong>, enabling scalable knowledge retention 
          and adaptive capabilities by mitigating task interference across diverse domains and modalities.
          Explore research directions including <strong>multimodal learning<strong>, <strong>resource-efficient learning<strong>, and 
          <strong>multimodal large language models<strong>, ultimately aiming toward Artificial General Intelligence (AGI).
        </p>
      </div>

      <div class="hero-links">
        <a class="pill" href="assets/cv.html" target="_blank" rel="noopener">
          <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"/>
            <polyline points="14 2 14 8 20 8"/><line x1="16" y1="13" x2="8" y2="13"/>
            <line x1="16" y1="17" x2="8" y2="17"/>
          </svg>
          CV
        </a>
        <a class="pill" href="https://scholar.google.com/citations?user=YOUR_ID" target="_blank" rel="noopener">
          <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <path d="M22 10v6M2 10l10-5 10 5-10 5z"/>
            <path d="M6 12v5c0 1.657 2.686 3 6 3s6-1.343 6-3v-5"/>
          </svg>
          Google Scholar
        </a>
        <a class="pill" href="https://github.com/Jin0316" target="_blank" rel="noopener">
          <svg viewBox="0 0 24 24" fill="currentColor">
            <path d="M12 2C6.477 2 2 6.484 2 12.017c0 4.425 2.865 8.18 6.839 9.504.5.092.682-.217.682-.483 0-.237-.008-.868-.013-1.703-2.782.605-3.369-1.343-3.369-1.343-.454-1.158-1.11-1.466-1.11-1.466-.908-.62.069-.608.069-.608 1.003.07 1.531 1.032 1.531 1.032.892 1.53 2.341 1.088 2.91.832.092-.647.35-1.088.636-1.338-2.22-.253-4.555-1.113-4.555-4.951 0-1.093.39-1.988 1.029-2.688-.103-.253-.446-1.272.098-2.65 0 0 .84-.27 2.75 1.026A9.564 9.564 0 0 1 12 6.844a9.59 9.59 0 0 1 2.504.337c1.909-1.296 2.747-1.027 2.747-1.027.546 1.379.202 2.398.1 2.651.64.7 1.028 1.595 1.028 2.688 0 3.848-2.339 4.695-4.566 4.943.359.309.678.92.678 1.855 0 1.338-.012 2.419-.012 2.747 0 .268.18.58.688.482A10.02 10.02 0 0 0 22 12.017C22 6.484 17.522 2 12 2z"/>
          </svg>
          GitHub
        </a>
      </div>
    </div>
  </div>
</section>



<!-- ═══════════ ABOUT / EDUCATION ═══════════ -->
<section id="about" class="section">
  <h2 class="section-title">Education</h2>
  <div class="edu-list">

    <div class="edu-item">
      <span class="edu-period">Mar. 2022 – Feb. 2026</span>
      <div>
        <p class="edu-degree">Ph.D. in Computer Science and Engineering</p>
        <p class="edu-school">
          Chung-Ang University &nbsp;·&nbsp;
          Advisor: <a href="https://vllab.cau.ac.kr/members/professor/">Prof. Eunwoo Kim</a>
        </p>
        <p class="edu-school" style="font-style:italic;">Thesis: Knowledge Association and Differentiation for Efficient Continual Learning</p>
      </div>
    </div>

    <div class="edu-item">
      <span class="edu-period">Mar. 2020 – Feb. 2022</span>
      <div>
        <p class="edu-degree">M.S. in Computer Science and Engineering</p>
        <p class="edu-school">
          Chung-Ang University &nbsp;·&nbsp;
          Advisor: <a href="https://vllab.cau.ac.kr/members/professor/">Prof. Eunwoo Kim</a>
        </p>
        <p class="edu-school" style="font-style:italic;">Thesis: Continual Learning without Negative Interference in a Deep Neural Network</p>
      </div>
    </div>

    <div class="edu-item">
      <span class="edu-period">Mar. 2015 – Feb. 2020</span>
      <div>
        <p class="edu-degree">B.S. in Electrical and Electronics Engineering</p>
        <p class="edu-school">Chung-Ang University</p>
      </div>
    </div>

  </div>
</section>

<!-- ═══════════ PUBLICATIONS ═══════════ -->
<section id="research" class="section">
  <h2 class="section-title">Publications</h2>

  <div class="pub-list">

    <!-- CVPR 2026 -->
    <div class="pub-item">
      <img class="pub-thumb" src="media/research/cvpr2026.png" alt="CVPR 2026" />
      <div class="pub-body">
        <p class="pub-title"><strong>Which Concepts to Forget and How to Refuse? Decomposing Concepts for Continual Unlearning in Large Vision-Language Models</strong></p>
        <p class="pub-venue"><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2026</em></p>
        <p class="pub-authors"><strong>Hyundong Jin</strong>, Dongyoon Han, and Eunwoo Kim</p>
      </div>
    </div>

    <!-- ICLR 2026 -->
    <div class="pub-item">
      <img class="pub-thumb" src="media/research/iclr2026.png" alt="ICLR 2026" />
      <div class="pub-body">
        <p class="pub-title"><strong>XIL: Cross-Expanding Incremental Learning</strong></p>
        <p class="pub-venue"><em>International Conference on Learning Representations (ICLR), 2026</em></p>
        <p class="pub-authors">Heayoun Choi, <strong>Hyundong Jin</strong>, and Eunwoo Kim</p>
        <div class="pub-links">
          <a href="https://openreview.net/forum?id=eaAGI1lIb4" target="_blank">Paper</a>
        </div>
      </div>
    </div>

    <!-- Neural Networks 2025 -->
    <div class="pub-item">
      <img class="pub-thumb" src="media/research/nn2025.png" alt="Neural Networks 2025" />
      <div class="pub-body">
        <p class="pub-title"><strong>Exploration and Exploitation in Continual Learning</strong></p>
        <p class="pub-venue"><em>Neural Networks (NN), 2025</em></p>
        <p class="pub-authors">Kiseong Hong, <strong>Hyundong Jin</strong>, Sungho Suh, and Eunwoo Kim</p>
        <div class="pub-links">
          <a href="https://www.sciencedirect.com/science/article/pii/S0893608025003235" target="_blank">Paper</a>
        </div>
      </div>
    </div>

    <!-- Pattern Recognition Letters 2025 -->
    <div class="pub-item">
      <img class="pub-thumb" src="media/research/prl2025.png" alt="Pattern Recognition Letters 2025" />
      <div class="pub-body">
        <p class="pub-title"><strong>Dataset Condensation with Coarse-to-Fine Regularization</strong></p>
        <p class="pub-venue"><em>Pattern Recognition Letters, 2025</em></p>
        <p class="pub-authors"><strong>Hyundong Jin</strong> and Eunwoo Kim</p>
        <div class="pub-links">
          <a href="https://www.sciencedirect.com/science/article/pii/S0167865524003726?via%3Dihub" target="_blank">Paper</a>
        </div>
      </div>
    </div>

    <!-- ICCV 2025 -->
    <div class="pub-item">
      <img class="pub-thumb" src="media/research/iccv2025.png" alt="ICCV 2025" />
      <div class="pub-body">
        <p class="pub-title"><strong>Instruction-Grounded Visual Projectors for Continual Learning of Generative Vision-Language Models</strong></p>
        <p class="pub-venue"><em>IEEE International Conference on Computer Vision (ICCV), 2025</em></p>
        <p class="pub-authors"><strong>Hyundong Jin</strong>, Hyung Jin Chang, and Eunwoo Kim</p>
        <p class="pub-note">Also presented at Korea Robotics Society (KROS) Physical AI Workshop, 2026</p>
        <div class="pub-links">
          <a href="https://openaccess.thecvf.com/content/ICCV2025/papers/Jin_Instruction-Grounded_Visual_Projectors_for_Continual_Learning_of_Generative_Vision-Language_Models_ICCV_2025_paper.pdf" target="_blank">Paper</a>
        </div>
      </div>
    </div>

    <!-- IEEE Access 2023 -->
    <div class="pub-item">
      <img class="pub-thumb" src="media/research/access2023.png" alt="IEEE Access 2023" />
      <div class="pub-body">
        <p class="pub-title"><strong>Task-Aware Dynamic Model Optimization for Multi-Task Learning</strong></p>
        <p class="pub-venue"><em>IEEE Access, 2023</em></p>
        <p class="pub-authors">Sujin Choi*, <strong>Hyundong Jin</strong>*, and Eunwoo Kim <span style="font-size:.8rem;">(* equal contribution)</span></p>
        <div class="pub-links">
          <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10345562" target="_blank">Paper</a>
        </div>
      </div>
    </div>

    <!-- ICCV 2023 -->
    <div class="pub-item">
      <img class="pub-thumb" src="media/research/iccv2023.png" alt="ICCV 2023" />
      <div class="pub-body">
        <p class="pub-title"><strong>Growing a Brain with Sparsity-Inducing Generation for Continual Learning</strong></p>
        <p class="pub-venue"><em>IEEE International Conference on Computer Vision (ICCV), 2023</em></p>
        <p class="pub-authors"><strong>Hyundong Jin</strong>, Gyeong-Hyeon Kim, Chanho Ahn, and Eunwoo Kim</p>
        <p class="pub-note">Also presented at Korean Conference on Computer Vision (KCCV), 2024</p>
        <div class="pub-links">
          <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Growing_a_Brain_with_Sparsity-Inducing_Generation_for_Continual_Learning_ICCV_2023_paper.pdf" target="_blank">Paper</a>
          <a href="https://github.com/Jin0316/GrowBrain" target="_blank">Code</a>
        </div>
      </div>
    </div>

    <!-- ECCV 2022 -->
    <div class="pub-item">
      <img class="pub-thumb" src="media/research/eccv2022.png" alt="ECCV 2022" />
      <div class="pub-body">
        <p class="pub-title"><strong>Helpful or Harmful: Inter-Task Association in Continual Learning</strong></p>
        <p class="pub-venue"><em>European Conference on Computer Vision (ECCV), 2022</em></p>
        <p class="pub-authors"><strong>Hyundong Jin</strong> and Eunwoo Kim</p>
        <div class="pub-links">
          <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136710518.pdf" target="_blank">Paper</a>
          <a href="https://github.com/Jin0316/Helpful-or-Harmful-Inter-Task-Association" target="_blank">Code</a>
        </div>
      </div>
    </div>

    <!-- IEEE Access 2022 -->
    <div class="pub-item">
      <img class="pub-thumb" src="media/research/access2022.png" alt="IEEE Access 2022" />
      <div class="pub-body">
        <p class="pub-title"><strong>Gating Mechanism in Deep Neural Networks for Resource-Efficient Continual Learning</strong></p>
        <p class="pub-venue"><em>IEEE Access, 2022</em></p>
        <p class="pub-authors"><strong>Hyundong Jin</strong>, Kimin Yoon, and Eunwoo Kim</p>
        <div class="pub-links">
          <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9695483" target="_blank">Paper</a>
        </div>
      </div>
    </div>

  </div>

  <!-- ── Ongoing Works ── -->
  <h3 style="font-size:.82rem;font-weight:700;letter-spacing:.08em;text-transform:uppercase;color:var(--muted);margin:1.8rem 0 .9rem;">Ongoing Works</h3>
  <div class="pub-list">

    <div class="pub-item">
      <div class="pub-thumb-ph" style="background:linear-gradient(135deg,#ffffff,#ffffff);">Comming soon!</div>
      <div class="pub-body">
        <p class="pub-title"><strong>Mind the Interference: Towards Robust Continual Learning Across Modalities</strong></p>
        <p class="pub-authors"><strong>Hyundong Jin</strong> and Eunwoo Kim</p>
        <p class="pub-venue"><em>To be updated</em></p>
      </div>
    </div>

    <div class="pub-item">
      <div class="pub-thumb-ph" style="background:linear-gradient(135deg,#ffffff,#ffffff);">Comming soon!</div>
      <div class="pub-body">
        <p class="pub-title"><strong>Action-incremental Learning for Temporal Action Segmentation</strong></p>
        <p class="pub-authors">Gyeong-Hyeon Kim, <strong>Hyundong Jin</strong>, Dongyoon Han, and Eunwoo Kim</p>
        <p class="pub-venue"><em>To be updated</em></p>
      </div>
    </div>

  </div>
</section>



<!-- ═══════════ PROJECTS ═══════════ -->
<section id="projects" class="section">
  <h2 class="section-title">Project Experiences</h2>
  <div class="project-list">

    <div class="project-item">
      <span class="project-period">2024 – 2025</span>
      <div>
        <p class="project-name">Multi-Modal Continual Learning with Context Understanding</p>
        <p class="project-funder">Funded by National Research Foundation</p>
      </div>
    </div>

    <div class="project-item">
      <span class="project-period">2024</span>
      <div>
        <p class="project-name">Time-Series Action Prediction and Segmentation</p>
        <p class="project-funder">Funded by HD Hyundai Construction Equipment</p>
      </div>
    </div>

    <div class="project-item">
      <span class="project-period">2021 – 2023</span>
      <div>
        <p class="project-name">Learning Transferable Task Knowledge and Planner for Service Robots</p>
        <p class="project-funder">Funded by Samsung Research Funding &amp; Incubation Center</p>
      </div>
    </div>

    <div class="project-item">
      <span class="project-period">2020 – 2024</span>
      <div>
        <p class="project-name">Development of AI for Self-Improving Competency-Aware Learning</p>
        <p class="project-funder">Funded by IITP</p>
      </div>
    </div>

    <div class="project-item">
      <span class="project-period">2020 – 2022</span>
      <div>
        <p class="project-name">Automated Deep Learning Technology for Multi-Task Learning</p>
        <p class="project-funder">Funded by National Research Foundation</p>
      </div>
    </div>

  </div>
  
<!-- ═══════════ MISC ═══════════ -->
<section id="others" class="section">
  <h2 class="section-title">Others</h2>

  <!-- Awards & Honors -->
  <h3 class="misc-heading">Awards &amp; Honors</h3>
  <ul class="misc-list">
    <li><span class="misc-main">Grand Prize, Big Data Utilization Contest</span> <span class="misc-sub">· Doosan Enerbility, 2023</span></li>
    <li><span class="misc-main">Excellence Prize, Big Data Utilization Contest</span> <span class="misc-sub">· HD Hyundai XiteSolution, 2023</span></li>
  </ul>

  <!-- Patents -->
  <h3 class="misc-heading">Patents</h3>
  <ul class="misc-list">
    <li><span class="misc-main">Apparatus and Method for Continuous Learning of Neural Networks· Republic of Korea. 10-2023-0156623</span></li>
    <li><span class="misc-main">A Neural Network Apparatus and Neural Network Learning Method for Performing Continuous Learning Using a Correlation Analysis Algorithm Between Tasks· Republic of Korea. 10-2022-0101187</span></li>
  </ul>

  <!-- Invited Talks -->
  <h3 class="misc-heading">Invited Talks</h3>
  <ul class="misc-list">
    <li><span class="misc-main">AhnLab</span> <span class="misc-sub">· Continual Learning, 2023</span></li>
    <li><span class="misc-main">Korean Computer Vision Society (KCVS)</span> <span class="misc-sub">· Continual Learning session, 2023</span></li>
    <li><span class="misc-main">Korean Artificial Intelligence Association (KAIA) &amp; NAVER</span> <span class="misc-sub">· CV / NLP session, 2022</span></li>
  </ul>

  <!-- Teaching Experiences -->
  <h3 class="misc-heading">Teaching Experiences</h3>
  <ul class="misc-list">
    <li><span class="misc-main">Machine Learning, Teaching Assistant (TA)</span> <span class="misc-sub">· Chung-Ang University, 2024</span></li>
    <li><span class="misc-main">Advanced Artificial Intelligence, Teaching Assistant (TA)</span> <span class="misc-sub">· Chung-Ang University, 2023</span></li>
    <li><span class="misc-main">Capstone Design, Teaching Assistant (TA)</span> <span class="misc-sub">· Chung-Ang University, 2021</span></li>
    <li><span class="misc-main">Visual Intelligence and its Applications</span> <span class="misc-sub">· ETRI, 2020</span></li>
    <li><span class="misc-main">Algorithms, Teaching Assistant (TA)</span> <span class="misc-sub">· Chung-Ang University, 2020</span></li>
  </ul>

  <!-- Academic Services -->
  <h3 class="misc-heading">Academic Services</h3>
  <ul class="misc-list">
    <li><span class="misc-main">Conference Reviewer</span> <span class="misc-sub">· CVPR, ICCV, ECCV, AAAI, ICLR, WACV, BMVC</span></li>
    <li><span class="misc-main">Journal Reviewer</span> <span class="misc-sub">· TNNLS</span></li>
  </ul>

</section>



</div><!-- /.wrap -->

<footer>
  &copy; 2025 Hyundong Jin &nbsp;·&nbsp; jude0316@cau.ac.kr
</footer>

<script src="assets/js/script.js"></script>
</body>
</html>
